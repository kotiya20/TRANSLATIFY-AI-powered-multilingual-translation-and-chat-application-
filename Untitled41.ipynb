{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3468a86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: gTTS in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (2.5.3)\n",
      "Requirement already satisfied: gradio in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (4.44.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (1.12.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (0.25.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gTTS) (8.1.7)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gTTS) (2.32.3)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (6.4.5)\n",
      "Requirement already satisfied: pydub in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (3.10.5)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (2.8.0)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (3.5.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.6.9)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (3.7.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: fastapi<1.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.110.3)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (1.3.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2024.9.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from click<8.2,>=7.1->gTTS) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from fastapi<1.0->gradio) (0.37.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: certifi in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from httpx>=0.24.1->gradio) (2022.12.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.7)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from pydantic>=2.0->gradio) (2.20.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from requests<3,>=2.27->gTTS) (2.0.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate gTTS gradio transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89edb8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from gtts import gTTS\n",
    "import torch\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01fbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b89586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c22a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b156a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "language_model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "try:\n",
    "    language_model = AutoModelForCausalLM.from_pretrained(language_model_name, trust_remote_code=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(language_model_name, trust_remote_code=True)\n",
    "    print(\"Model and tokenizer loaded successfully!\")\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError loading model: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e5b067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (1): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (2): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (3): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (4): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (5): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (6): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (7): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (8): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (9): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (10): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (11): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (12): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (13): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (14): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (15): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (16): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (17): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (18): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (19): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (20): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (21): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (22): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (23): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (24): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (25): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (26): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "      (27): Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a7e68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(input_text, action):\n",
    "    if action == \"Translate to English\":\n",
    "        prompt = f\"Please translate the following text into English：{input_text}\"\n",
    "        lang = \"en\"\n",
    "    elif action == \"Translate to Chinese\":\n",
    "        prompt = f\"Please translate the following text into Chinese：{input_text}\"\n",
    "        lang = \"zh-cn\"\n",
    "    elif action == \"Translate to Japanese\":\n",
    "        prompt = f\"Please translate the following text into Japanese：{input_text}\"\n",
    "        lang = \"ja\"\n",
    "    elif action == \"Translate to Hindi\":\n",
    "        prompt = f\"Please translate the following text into Hindi：{input_text}\"\n",
    "        lang = \"hi\"\n",
    "    elif action == \"Translate to Marathi\":\n",
    "        prompt = f\"Please translate the following text into Marathi：{input_text}\"\n",
    "        lang = \"mr\"\n",
    "    else:\n",
    "        prompt = input_text\n",
    "        lang = \"en\"\n",
    "    \n",
    "    # Rest of your tokenization and model input logic here\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = language_model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=512\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    output_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return output_text, lang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36397df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(text, lang):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    filename = \"output_audio.mp3\"\n",
    "    tts.save(filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79b045f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def handle_interaction(input_text, action):\n",
    "    output_text, lang = process_input(input_text, action)\n",
    "    audio_filename = text_to_speech(output_text, lang)\n",
    "    return output_text, audio_filename\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b435d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_options = [\"Translate to English\", \"Translate to Chinese\", \"Translate to Japanese\", \"Translate to Hindi\", \"Translate to Marathi\", \"Chat\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9961eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=handle_interaction,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"input text\"),\n",
    "        gr.Dropdown(action_options, label=\"select action\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"output text\"),\n",
    "        gr.Audio(label=\"output audio\")\n",
    "    ],\n",
    "    title=\"TRANSLATIFY\",\n",
    "    description=\"Translate input text or chat based on the selected action.\",\n",
    "    theme= \"gradio/soft\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13bcb125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: gTTS in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (2.5.3)\n",
      "Requirement already satisfied: gradio in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (4.44.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (1.12.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from accelerate) (0.25.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gTTS) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gTTS) (8.1.7)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.6.9)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (3.10.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (2.8.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (3.5.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: fastapi<1.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.110.3)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (6.4.5)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: pydub in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2024.9.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from click<8.2,>=7.1->gTTS) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from fastapi<1.0->gradio) (0.37.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from httpx>=0.24.1->gradio) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.7)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from pydantic>=2.0->gradio) (2.20.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from requests<3,>=2.27->gTTS) (2.0.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yash kotiya\\anaconda3\\anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate gTTS gradio transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4563804b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "Running on public URL: https://28a2efc8dee67e9861.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://28a2efc8dee67e9861.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c73b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2180b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
